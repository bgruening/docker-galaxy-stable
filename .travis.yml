sudo: required

language: python
python: 2.7

services:
  - docker

env:
  matrix:
    - TOX_ENV=py27
    - COMPOSE_SLURM=True
    - COMPOSE_SLURM_SINGULARITY=True
    # Compose version with Condor submitting Docker jobs
    - COMPOSE_CONDOR_DOCKER=True
    - KUBE=True
  global:
    - secure: "SEjcKJQ0NGXdpFxFhLVlyJmiBvgiLtR5Uufg90Vm3owKlMy0NSfIrOR+2dwNniqOp7QI3eVepnqjid/Ka0QStzVqMCe55OLkJ/TbTHnMLpbtY63mpGfogVRvxMMAVpzLpcQqtJFORZmO/MIWSLlBiXMMzOg3+tbXvQXmL17Rbmw="

matrix:
  allow_failures:
    - env: KUBE=True

git:
  submodules: false

before_install:
  - set -e
  - export GALAXY_HOME=/home/galaxy
  - export GALAXY_USER=admin@galaxy.org
  - export GALAXY_USER_EMAIL=admin@galaxy.org
  - export GALAXY_USER_PASSWD=admin
  - export BIOBLEND_GALAXY_API_KEY=admin
  - export BIOBLEND_GALAXY_URL=http://localhost:8080
  - export COMPOSE_DIR="${TRAVIS_BUILD_DIR}/compose"

  - sudo apt-get update -qq
  - sudo apt-get install docker-ce --no-install-recommends -y -o Dpkg::Options::="--force-confmiss" -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confnew"
  # xvfb is needed for selenium
  - sudo apt-get install xvfb sshpass --no-install-recommends -y
  # selenium headless mode
  - pip install pyvirtualdisplay selenium requests pyyaml
  - wget https://github.com/mozilla/geckodriver/releases/download/v0.19.1/geckodriver-v0.19.1-linux64.tar.gz
  - tar -xzf geckodriver-v0.19.1-linux64.tar.gz && sudo mv geckodriver /usr/bin/geckodriver && sudo chmod a+x /usr/bin/geckodriver

  - docker --version
  - docker info
  # Build a k8s cluster
  - |
    if [ "${KUBE}" ]
    then
      # setup k8s, we will do this before building Galaxy because it takes some time and hopefully we can do both in prallel
      gimme 1.8
      source ~/.gimme/envs/go1.8.env
      sudo ln -s /home/travis/.gimme/versions/go1.7.linux.amd64/bin/gofmt /usr/bin/gofmt
      sudo ln -s /home/travis/.gimme/versions/go1.7.linux.amd64/bin/go /usr/bin/go
      go version
      mkdir ../kubernetes
      wget -q -O - https://github.com/kubernetes/kubernetes/archive/master.tar.gz | tar xzf - --strip-components=1 -C ../kubernetes
      cd ../kubernetes
      # k8s API port is running by default on 8080 as Galaxy, can this to 8000
      export API_PORT=8000
      ./hack/install-etcd.sh
      sudo ln -s `pwd`/third_party/etcd/etcd /usr/bin/etcd
      sudo ln -s `pwd`/third_party/etcd/etcdctl /usr/bin/etcdctl
      # this needs to run in backgroud later, for now try to see the output
      sudo ./hack/local-up-cluster.sh &
      cd ../docker-galaxy-stable
    fi


  # load all configurations needed for SLURM testing
  - |
    if [ "${COMPOSE_SLURM}" ]
    then
      # The compose file recognises ENV vars to change the defaul behavior
      cd ${COMPOSE_DIR}
      ln -sf .env_slurm .env
    fi

  # load all configurations needed for SLURM testing
  - |
    if [ "${COMPOSE_SLURM_SINGULARITY}" ]
    then
      # The compose file recognises ENV vars to change the defaul behavior
      cd ${COMPOSE_DIR}
      ln -sf .env_slurm_singularity .env
    fi

  # load all configurations needed for Condor and Docker
  - |
    if [ "${COMPOSE_CONDOR_DOCKER}" ]
    then
      # The compose file recognises ENV vars to change the defaul behavior
      cd ${COMPOSE_DIR}
      ln -sf .env_htcondor_docker .env

      # Galaxy needs to a full path for the the jobs, in- and outputs.
      # Do we want to run each job in it's own container and this container uses the host
      # container engine (not Docker in Docker) then the path to all files inside and outside
      # of the container needs to be the same.
      sudo mkdir /export
      sudo chmod 777 /export
      sudo chown 1450:1450 /export
    fi

  # Installing kompose to convert the docker-compose YAML file
  - |
    if [ "${KUBE}" ]
    then
        curl -L https://github.com/kubernetes-incubator/kompose/releases/download/v0.5.0/kompose-linux-amd64 -o kompose
        chmod +x kompose
        sudo mv ./kompose /usr/bin/kompose
    fi

  # start building this repo
  - git submodule update --init --recursive
  - sudo chown 1450 /tmp && sudo chmod a=rwx /tmp
  - |
    if [ "${COMPOSE_SLURM}" ] || [ "${COMPOSE_CONDOR_DOCKER}" ] || [ "${KUBE}" ] || [ "${COMPOSE_SLURM_SINGULARITY}" ]
    then
        pip install docker-compose galaxy-parsec
        export WORKING_DIR="$TRAVIS_BUILD_DIR/compose"
        export DOCKER_RUN_CONTAINER="galaxy-web"
        INSTALL_REPO_ARG="--galaxy-url http://localhost:80"
        SAMPLE_TOOLS=/export/config/sample_tool_list.yaml
        cd "$WORKING_DIR"
        ./buildlocal.sh
        export COMPOSE_PROJECT_NAME=galaxy_compose
        docker-compose up -d

        until docker-compose exec galaxy-web ps -fC uwsgi
        do
          echo "sleeping for 20 seconds"
          sleep 20
          docker-compose logs --tail 10
        done

        if [ "${COMPOSE_CONDOR_DOCKER}" ]
        then
            # turn down the slurm service
            echo "Stopping SLURM container"
            docker-compose stop galaxy-slurm
            sleep 30
        fi
        
        if [ "${COMPOSE_SLURM}" ] || [ "${COMPOSE_SLURM_SINGULARITY}" ]
        then
            # turn down the htcondor services
            echo "Stopping HT-Condor containers"
            docker-compose stop galaxy-htcondor galaxy-htcondor-executor galaxy-htcondor-executor-big
            sleep 30
        fi

        if [ "${COMPOSE_SLURM_SINGULARITY}" ]
        then
            # docker-compose is already started and has pre-populated the /export dir
            # we now turn it down again and copy in an example tool with tool_conf.xml and 
            # a test singularity image. If we copy this from the beginning, the magic Docker Galax startup
            # script will not work as it detects something in /export/
            docker-compose down
            sleep 10
            echo "Downloading Singularity test files and images."
            sudo mkdir -p /export/database/container_images/singularity/mulled/
            sudo curl -L -o /export/database/container_images/singularity/mulled/samtools:1.4.1--0 https://github.com/bgruening/singularity-galaxy-tests/raw/master/samtools:1.4.1--0
            sudo curl -L -o /export/cat_tool_conf.xml https://github.com/bgruening/singularity-galaxy-tests/raw/master/cat_tool_conf.xml
            sudo curl -L -o /export/cat.xml https://github.com/bgruening/singularity-galaxy-tests/raw/master/cat.xml

            docker-compose up -d
            sleep 60

            parsec init --api_key admin --url localhost:8080
            HISTORY_ID=$(parsec histories create_history | jq .id -r)
            DATASET_ID=$(parsec tools paste_content 'asdf' $HISTORY_ID | jq '.outputs[0].id' -r)
            OUTPUT_ID=$(parsec tools run_tool $HISTORY_ID cat '{"input1": {"src": "hda", "id": "'$DATASET_ID'"}}' | jq '.outputs | .[0].id' -r)
            sleep 15
            # we are lucky that the out test image has a small bug and always prints a warning. We use this to grep if the tool was running with SINGULARITY
            # WARNING Bind file destination does not exist in container /usr/local/var/singularity/mnt/overlay/final/etc/...
            parsec datasets show_dataset $OUTPUT_ID | jq .misc_info | grep singularity

        fi
        
        docker-compose logs --tail 50
        # Define start functions
        docker_exec() {
          cd $WORKING_DIR
          docker-compose exec galaxy-web "$@"
        }
        docker_exec_run() {
          cd $WORKING_DIR
          docker-compose exec galaxy-web "$@"
        }
        docker_run() {
          cd $WORKING_DIR
          docker-compose run "$@"
        }
    else
        export WORKING_DIR="$TRAVIS_BUILD_DIR"
        export DOCKER_RUN_CONTAINER="quay.io/bgruening/galaxy"
        INSTALL_REPO_ARG=""
        SAMPLE_TOOLS=$GALAXY_HOME/ephemeris/sample_tool_list.yaml
        cd "$WORKING_DIR"
        docker build -t quay.io/bgruening/galaxy galaxy/
        mkdir local_folder
        docker run -d -p 8080:80 -p 8021:21 -p 8022:22 \
            --name galaxy \
            --privileged=true \
            -v `pwd`/local_folder:/export/ \
            -e GALAXY_CONFIG_ALLOW_USER_DATASET_PURGE=True \
            -e GALAXY_CONFIG_ALLOW_LIBRARY_PATH_PASTE=True \
            -e GALAXY_CONFIG_ENABLE_USER_DELETION=True \
            -e GALAXY_CONFIG_ENABLE_BETA_WORKFLOW_MODULES=True \
            -v /tmp/:/tmp/ \
            quay.io/bgruening/galaxy
        sleep 30
        docker logs galaxy
        # Define start functions
        docker_exec() {
          cd $WORKING_DIR
          docker exec -t -i galaxy "$@"
        }
        docker_exec_run() {
          cd $WORKING_DIR
          docker run quay.io/bgruening/galaxy "$@"
        }
        docker_run() {
          cd $WORKING_DIR
          docker run "$@"
        }

    fi
  - docker ps

script:
  - set -e
  # Test submitting jobs to an external slurm cluster
  - |
      if [ ! "${COMPOSE_SLURM}" ] && [ ! "${KUBE}" ] && [ ! "${COMPOSE_CONDOR_DOCKER}" ] && [ ! "${COMPOSE_SLURM_SINGULARITY}" ]
      then
        # For compose slurm is already included and thus tested
        cd $TRAVIS_BUILD_DIR/test/slurm/ && bash test.sh && cd $WORKING_DIR
      fi
  # Test submitting jobs to an external gridengine cluster
  - |
      if [ ! "${COMPOSE_SLURM}" ] && [ ! "${KUBE}" ] && [ ! "${COMPOSE_CONDOR_DOCKER}" ] && [ ! "${COMPOSE_SLURM_SINGULARITY}" ]
      then
        # This test is not testing compose, thus disabled
        cd $TRAVIS_BUILD_DIR/test/gridengine/ && bash test.sh && cd $WORKING_DIR
      fi
  # Test Web api
  - curl -v --fail $BIOBLEND_GALAXY_URL/api/version

  # Test self-signed HTTPS
  - docker_run -d --name httpstest -p 443:443 -e "USE_HTTPS=True" $DOCKER_RUN_CONTAINER
  - sleep 90s && curl -v -k --fail https://127.0.0.1:443/api/version
  - echo | openssl s_client -connect 127.0.0.1:443 2>/dev/null | openssl x509 -issuer -noout| grep selfsigned
  - docker logs httpstest && docker stop httpstest && docker rm httpstest

  # Test FTP Server upload
  - date > time.txt && curl -v --fail -T time.txt ftp://localhost:8021 --user $GALAXY_USER:$GALAXY_USER_PASSWD || true
  # Test FTP Server get
  - curl -v --fail ftp://localhost:8021 --user $GALAXY_USER:$GALAXY_USER_PASSWD
  
  # Test CVMFS
  - docker_exec bash -c "service autofs start"
  - docker_exec bash -c "cvmfs_config chksetup"
  - docker_exec bash -c "ls /cvmfs/data.galaxyproject.org/byhand"

  # Test SFTP Server
  - sshpass -p $GALAXY_USER_PASSWD sftp -v -P 8022 -o User=$GALAXY_USER -o "StrictHostKeyChecking no" localhost <<< $'put time.txt'

  # Run a ton of BioBlend test against our servers.
  - cd $TRAVIS_BUILD_DIR/test/bioblend/ && . ./test.sh && cd $WORKING_DIR/

  # Test the 'old' tool installation script
  - docker_exec_run bash -c "install-repository $INSTALL_REPO_ARG '--url https://toolshed.g2.bx.psu.edu -o iuc --name bedtools --panel-section-name BEDTools'"
  - |
    if [ "${COMPOSE_SLURM}" ] || [ "${KUBE}" ] || [ "${COMPOSE_CONDOR_DOCKER}" ] || [ "${COMPOSE_SLURM_SINGULARITY}" ]
    then
        # Test without install-repository wrapper
        sleep 10
        docker_exec_run bash -c 'cd $GALAXY_ROOT && python ./scripts/api/install_tool_shed_repositories.py --api admin -l http://localhost:80 --url https://toolshed.g2.bx.psu.edu -o devteam --name cut_columns --panel-section-name BEDTools'
    fi
  # Test the 'new' tool installation script
  #  - docker_exec bash -c "install-tools $GALAXY_HOME/ephemeris/sample_tool_list.yaml"
  - |
    if [ "${COMPOSE_SLURM}" ] || [ "${KUBE}" ] || [ "${COMPOSE_CONDOR_DOCKER}" ] || [ "${COMPOSE_SLURM_SINGULARITY}" ]
    then
        # Compose uses the online installer (uses the running instance)
        sleep 10
        docker_exec_run shed-install -g "http://localhost:80" -a admin -t "$SAMPLE_TOOLS"
    else
      docker_exec_run install-tools "$SAMPLE_TOOLS"
    fi
  # Test the Conda installation
  - docker_exec_run bash -c 'export PATH=$GALAXY_CONFIG_TOOL_DEPENDENCY_DIR/_conda/bin/:$PATH && conda --version && conda install samtools -c bioconda --yes'
  # Test Docker in Docker, used by Interactive Environments; This needs to be at the end as Docker takes some time to start.
  - docker_exec docker info

  # Selenium UI tests
  - docker run -d -p 4444:4444 -v /dev/shm:/dev/shm selenium/standalone-firefox
  - sleep 30s
  - mkdir ./selenium_galaxy/
  - wget -q -O - https://github.com/galaxyproject/galaxy/archive/release_17.01.tar.gz | tar xzf - --strip-components=1 -C ./selenium_galaxy/
  - wget https://raw.githubusercontent.com/galaxyproject/galaxy/dev/config/plugins/tours/core.galaxy_ui.yaml
  - ./selenium_galaxy/scripts/dump_tour.py -o selenium_img --selenium-headless --selenium-browser FIREFOX --galaxy_url http://localhost:8080 core.galaxy_ui.yaml
  - ls -l selenium_img

  # Check if the database image matches the current galaxy version
  - |
      if [ "${COMPOSE_SLURM}" ] || [ "${KUBE}" ] || [ "${COMPOSE_CONDOR_DOCKER}" ] || [ "${COMPOSE_SLURM_SINGULARITY}" ]
      then
        cd $WORKING_DIR && bash ./dumpsql.sh
        git diff --exit-code $WORKING_DIR/galaxy-postgres/init-galaxy-db.sql.in || ( echo "Database dump does not equal dump in repository" && false )
      fi


after_success:
  - |
    if [ "$TRAVIS_PULL_REQUEST" == "false" -a "$TRAVIS_BRANCH" == "master" ]
    then
      if [ ! "${COMPOSE_SLURM}" ] && [ ! "${KUBE}" ] && [ ! "${COMPOSE_CONDOR_DOCKER}" ] && [ ! "${COMPOSE_SLURM_SINGULARITY}" ]
      then
        cd ${TRAVIS_BUILD_DIR}
        echo "Generate and deploy html documentation"
        ./docs/bin/deploy_docs
      fi
    fi


notifications:
  webhooks:
    urls:
      - https://webhooks.gitter.im/e/559f5480ac7a4ef238af
    on_success: change
    on_failure: always
    on_start: never
