version: '3'
services:
  # proftpd container
  galaxy-proftpd:
    # build: galaxy-proftpd
    image: quay.io/bgruening/galaxy-proftpd:${TAG_PROFTPD:-latest}
    env_file: .env
    environment:
        - proftpd_db_connection=galaxy@galaxy-postgres
        - proftpd_db_username=galaxy
        - proftpd_db_password=chaopagoosaequuashie
        - proftpd_files_dir=${EXPORT_DIR:-/export}/ftp/
        - proftpd_use_sftp=True
        - proftpd_generate_ssh_key=False
        - proftpd_passive_port_low=30000
        - proftpd_passive_port_high=30010
    container_name: galaxy-proftpd
    hostname: galaxy-proftpd
    volumes:
        - ${EXPORT_DIR:-/export}/:/export
    expose:
        - 21
        - 22
    ports:
        - "8021:21"
        - "8022:22"
        - "30000-30010:30000-30010"
    restart: always
    depends_on:
      - galaxy-postgres
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
            - node.role == ${NODE_ROLE:-manager}
    labels:
        kompose.service.type: nodeport

  galaxy-postgres:
    # If you are using the official postgres image, it needs to be populated by calling
    # docker-compose run galaxy install_db.sh
    # on first run
    image: quay.io/bgruening/galaxy-postgres:${TAG_POSTGRES:-latest}
    container_name: galaxy-postgres
    hostname: galaxy-postgres
    env_file: .env
    environment:
        - POSTGRES_PASSWORD=chaopagoosaequuashie
        - POSTGRES_USER=galaxy
        - POSTGRES_DB=galaxy
    volumes:
        - ${EXPORT_DIR:-/export}/postgres/:/var/lib/postgresql/data
    depends_on:
      - galaxy-init
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-manager}


  # PostgreSQL admin suite
  pgadmin4:
    image: thajeztah/pgadmin4
    container_name: pgadmin4
    env_file: .env
    ports:
        - "5050:5050"
    links:
        - galaxy-postgres
    # ToDO, not sure why this is failing
    #volumes:
        #- ./pgadmin:/pgadmin
    restart: unless-stopped
    networks:
      - galaxy
    depends_on:
      - galaxy-postgres
    deploy:
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-manager}
    labels:
        kompose.service.type: nodeport

  # SLURM container - this is your compute cluster :)
  galaxy-slurm:
    # build: galaxy-slurm
    image: quay.io/bgruening/galaxy-slurm:${TAG:-latest}
    privileged: True
    env_file: .env
    #${PRIVILEGED_SLURM_CONTAINER:-False}
    environment: {}
    container_name: galaxy-slurm
    hostname: galaxy-slurm
    volumes:
        - ${EXPORT_DIR:-/export}/:/export
    restart: unless-stopped
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-worker}


  # This container initializes the galaxy export.
  galaxy-init:
    # build: galaxy-init
    image: quay.io/bgruening/galaxy-init:${TAG:-latest}
    container_name: galaxy-init
    hostname: galaxy-init
    env_file: .env
    volumes:
        # This is the directory where all your files from Galaxy will be stored
        # on your host system. By default this is 'export' in your current working dir
        - ${EXPORT_DIR:-/export}/:/export/
    networks:
      - galaxy
    deploy:
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-manager}


  galaxy-htcondor:
    image: quay.io/bgruening/galaxy-htcondor:${TAG:-latest}
    container_name: galaxy-htcondor
    hostname: galaxy-htcondor
    env_file: .env
    #fix the multiple IP addresses issue cause by swarm
    command: bash -c 'echo "NETWORK_INTERFACE = $$(hostname -i | cut --delimiter " " --fields 2)" >> /etc/condor/config.d/fix-network && /usr/bin/supervisord'
    volumes:
        - ${EXPORT_DIR:-/export}/:/export
    restart: unless-stopped
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-worker}


  galaxy-htcondor-executor:
    image: quay.io/bgruening/galaxy-htcondor-executor:${TAG:-latest}
    # privileged is needed to run Docker jobs, moreover HTCondor wants
    # a RW cgroups mount. A RO cgroups mount throws an error in ProcD for running jobs.
    privileged: True
    #${PRIVILEGED_CONDOR_CONTAINER:-False}
    env_file: .env
    environment:
        - CONDOR_HOST=galaxy-htcondor
    #fix the multiple IP addresses issue cause by swarm
    command: bash -c 'echo "NETWORK_INTERFACE = $$(hostname -i | cut --delimiter " " --fields 2)" >> /etc/condor/config.d/fix-network && /usr/bin/startup.sh'
    volumes:
        - ${EXPORT_DIR:-/export}/:/export
        - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-worker}


  galaxy-htcondor-executor-big:
    image: quay.io/bgruening/galaxy-htcondor-executor:${TAG:-latest}
    # privileged is needed to run Docker jobs, moreover HTCondor wants
    # a RW cgroups mount. A RO cgroups mount throws an error in ProcD for running jobs.
    privileged: True
    #${PRIVILEGED_CONDOR_CONTAINER:-False}
    env_file: .env
    environment:
        - CONDOR_HOST=galaxy-htcondor
        - CONDOR_CPUS=2
        - CONDOR_MEMORY=2048
    #fix the multiple IP addresses issue cause by swarm
    command: bash -c 'echo "NETWORK_INTERFACE = $$(hostname -i | cut --delimiter " " --fields 2)" >> /etc/condor/config.d/fix-network && /usr/bin/startup.sh'
    volumes:
        - ${EXPORT_DIR:-/export}/:/export
        - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-worker}


  # Message queue for better performance
  rabbitmq:
    image: rabbitmq:alpine
    container_name: galaxy-rabbitmq
    hostname: rabbitmq
    env_file: .env
    environment:
        - RABBITMQ_DEFAULT_USER=galaxy
        - RABBITMQ_DEFAULT_PASS=vaiJa3ieghai2ief0jao
        - RABBITMQ_DEFAULT_VHOST=galaxy
    volumes:
        - ${EXPORT_DIR:-/export}/rabbitmq:/var/lib/rabbitmq
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-worker}


  # Grafana and InfluxDB for statistics
  influxdb:
    image: influxdb:1.4-alpine
    env_file: .env
    environment:
        - RABBITMQ_DEFAULT_USER=galaxy
        - RABBITMQ_DEFAULT_PASS=vaiJa3ieghai2ief0jao
        - RABBITMQ_DEFAULT_VHOST=galaxy
    volumes:
        - ${EXPORT_DIR:-/export}/influxdb:/var/lib/influxdb
    networks:
      - galaxy
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == ${NODE_ROLE:-worker}

  grafana:
    image: quay.io/bgruening/galaxy-grafana:${TAG:-latest}
    env_file: .env
    volumes:
        - ${EXPORT_DIR:-/export}/grafana:/var/lib/grafana
    networks:
      - galaxy
    ports:
        - "3000:3000"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
            - node.role == ${NODE_ROLE:-worker}

  # This container provides the galaxy uwsgi webhandlers, job handlers, nginx
  galaxy-web:
    # build: galaxy-web
    image: quay.io/bgruening/galaxy-web:${TAG:-latest}
    env_file: .env
    environment:
        # In case the galaxy-init container is not used, you need to include "sleeplock" to NONUSE
        - NONUSE=proftpd,postgres,slurmd,slurmctld
        - GALAXY_DEFAULT_ADMIN_USER=admin
        - GALAXY_DEFAULT_ADMIN_EMAIL=admin@galaxy.org
        - GALAXY_DEFAULT_ADMIN_PASSWORD=admin
        - GALAXY_DEFAULT_ADMIN_KEY=admin
        - GALAXY_HANDLER_NUMPROCS=2
        - UWSGI_PROCESSES=4
        - GALAXY_CONFIG_ALLOW_USER_DATASET_PURGE=True
        - GALAXY_CONFIG_ALLOW_LIBRARY_PATH_PASTE=True
        - GALAXY_CONFIG_ENABLE_USER_DELETION=True
        - GALAXY_CONFIG_ENABLE_BETA_WORKFLOW_MODULES=True
        - GALAXY_CONFIG_DATABASE_CONNECTION=postgresql://galaxy:chaopagoosaequuashie@galaxy-postgres/galaxy?client_encoding=utf8
        - GALAXY_CONFIG_TOOL_DATA_TABLE_CONFIG_PATH=/etc/galaxy/tool_data_table_conf.xml
        # Configurate admin and master api key. Can be overridden in galaxy.yml
        - GALAXY_CONFIG_ADMIN_USERS=admin@galaxy.org
        - GALAXY_CONFIG_MASTER_API_KEY=HSNiugRFvgT574F43jZ7N9F3
        - GALAXY_CONFIG_DATABASE_AUTO_MIGRATE=${GALAXY_CONFIG_DATABASE_AUTO_MIGRATE:-false}
        - GALAXY_CONFIG_AMQP_INTERNAL_CONNECTION=amqp://galaxy:vaiJa3ieghai2ief0jao@rabbitmq/galaxy
        # Condor
        - GALAXY_DESTINATIONS_DEFAULT=${GALAXY_DESTINATIONS_DEFAULT:-slurm_cluster}
        - GALAXY_RUNNERS_ENABLE_CONDOR=${GALAXY_RUNNERS_ENABLE_CONDOR:-False}
        - GALAXY_RUNNERS_ENABLE_SLURM=${GALAXY_RUNNERS_ENABLE_SLURM:-False}
        - GALAXY_RUNNERS_ENABLE_K8=${GALAXY_RUNNERS_ENABLE_K8:-False}
        - ENABLE_CONDOR=true
        - CONDOR_HOST=galaxy-htcondor
        - GALAXY_CONDOR_UNIVERSE=vanilla
        - GALAXY_DOCKER_ENABLED=${GALAXY_DOCKER_ENABLED:-False}
        - GALAXY_CONFIG_CLEANUP_JOB=${GALAXY_CONFIG_CLEANUP_JOB:-onsuccess}
        - GALAXY_CONFIG_ENABLE_BETA_MULLED_CONTAINERS=${GALAXY_CONFIG_ENABLE_BETA_MULLED_CONTAINERS:-False}
        - GALAXY_CONFIG_TOOL_CONFIG_FILE=${GALAXY_CONFIG_TOOL_CONFIG_FILE:-config/tool_conf.xml.sample,config/shed_tool_conf.xml}
        - GALAXY_SINGULARITY_VOLUMES=${GALAXY_SINGULARITY_VOLUMES:-\$tool_directory:ro,\$working_directory:rw,\$default_file_path:rw}

        # Proxy Prefix settings
        #- PROXY_PREFIX=${PROXY_PREFIX:-""}
        #- GALAXY_CONFIG_NGINX_X_ACCEL_REDIRECT_BASE=${GALAXY_CONFIG_NGINX_X_ACCEL_REDIRECT_BASE:-""}
        #- GALAXY_CONFIG_NGINX_X_ARCHIVE_FILES_BASE=${GALAXY_CONFIG_NGINX_X_ARCHIVE_FILES_BASE:-""}
        #- GALAXY_CONFIG_NGINX_UPLOAD_PATH=${GALAXY_CONFIG_NGINX_UPLOAD_PATH:-""}
        # k8s
        #- GALAXY_DESTINATIONS_DOCKER_DEFAULT=${GALAXY_DESTINATIONS_DOCKER_DEFAULT:-slurm_cluster}
        #- GALAXY_DESTINATIONS_NO_DOCKER_DEFAULT=${GALAXY_DESTINATIONS_NO_DOCKER_DEFAULT:-slurm_cluster}
        #- GALAXY_CONFIG_CONTAINERS_RESOLVERS_CONFIG_FILE=${GALAXY_CONFIG_CONTAINERS_RESOLVERS_CONFIG_FILE:-None}
        # Hack for pykube - https://github.com/kelproject/pykube/issues/29
        - PYKUBE_KUBERNETES_SERVICE_HOST=kubernetes
        # Just for testing...
        #- GALAXY_CONFIG_OVERRIDE_TOOL_CONFIG_FILE=/export/galaxy-central/test/functional/tools/samples_tool_conf.xml
    container_name: galaxy-web
    hostname: galaxy
    privileged: True
    #Fix the multiple ID addresses issue cause by swarm
    command: bash -c 'echo "NETWORK_INTERFACE = $$(hostname -i | cut --delimiter " " --fields 2)" >> /etc/condor/config.d/fix-network && /usr/bin/startup'
    networks:
      - galaxy
    ports:
        - "${GALAXY_PORT:-8080}:80" # nginx
    volumes:
        # This is the directory where all your files from Galaxy will be stored
        # on your host system
        - ${EXPORT_DIR:-/export}/:/export/
        - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - galaxy-init
      - galaxy-postgres
      - rabbitmq
    deploy:
      placement:
        constraints:
            - node.role == ${NODE_ROLE:-manager}
    labels:
        kompose.service.type: nodeport

networks:
    galaxy:
